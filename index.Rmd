---
title: "Odds & Ends: Introducing Probability & Decision with a Visual Emphasis"
author: "Jonathan Weisberg"
---

# Preface {-}

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  dev.args = list(bg = "transparent")
)
library(tufte)
library(dplyr)
library(ggplot2)
library(ggforce)
theme_set(theme_minimal())
```

This book is designed for introductory philosophy courses on probability, decision, and inductive logic. It is based on a fairly standard such course I teach at the University of Toronto, where we offer "Probability & Inductive Logic" in the second year as a counterpart to the usual deductive logic intro.$\,$

The book assumes no knowledge of deductive logic. The little that's used is introduced in the early chapters. In fact almost no formal background is presumed. Very simple high school algebra is all that's required.

The book is inspired and influenced by well-known predecessors like Brian Skyrms' *Choice & Chance* and Ian Hacking's *An Introduction to Probability and Inductive Logic*. Both texts are widely used, and with very good reason: they are excellent. I've used them both many times, with great success. This book is partly just an attempt to blend my favourite aspects of each, in the sequence and style I prefer.

But I also hope it offers more objective benefits:

1. This book is open access, hence free.
2. It's also open source, so other instructors can modify it to their liking.
3. It's available in both PDF and HTML, so it can be printed or read on a range of devices comfortably.
4. It emphasizes visual explanations and techniques, to make the material more approachable.
5. It livens up the text with hyperlinks, animations, interactive tools, and margin notes that highlight points of history and curiosity.


`r newthought("The book is divided")` into three main parts. The first explains the basics of logic and probability, the second covers basic decision theory, and the last introduces the Bayesian and frequent schools of thought. Optional chapters in the Appendix cover the axiomatic construction of probability theory, Hume's problem of induction, and Goodman's new ridle of induction.

When I teach this material, I aim to leave students with a clearer view of their society's statistical realities. Media bombard students with nutritional fads, overhyped "significant" findings, fantastical (or fantastical sounding) advances in machine learning and artificial intelligence, and more. I want them to understand what these items do and don't mean. I don't want them to become too skeptical or jaded about scientific research just because the news overhypes nutritional studies, only to cash in on the backlash. But neither do I want them to be naive science-worshippers, unaware of the ideologies and assumptions that underpin the contemporary scientific worldview.

So I think of the course as building up a suite of skills and tools, yet ending with a mystery. The mystery is revealed in the final showdown between the Bayesian and frequentist schools, each of which is left facing an ultimate paradox. The Bayesian school struggles with the problem of priors, exemplified in Bertrand's paradox. The frequentist school then tries to work prior-free with significance testing, only to find that priors bite back in Lindley's paradox.

I usually get a mix of students in my course, with different ideological inclinations and varying levels of background. For some the technical material is easy, even review. For others, a healthy skepticism about scientific methods and discourses comes naturally. My goal is to get these students all more or less on the same page.

By the end of the course, students with little formal background have a bevy of tools for thinking about uncertainty. They can understand much more of the statistical and scientific discourse they encounter. And hopefully they have a greater appreciation for the value of formal methods. Students who already have strong formal tools and skills will, I hope, better understand their limitations. I want them to understand why these tools leave big questions open---not just philosophically, but also in very pressing, practical ways.

`r newthought("The book")` was made with the `bookdown` package created by Yihui Xie. It's a wonderful tool, built on a bunch of other technologies I love, especially the R programming language and the pandoc conversion tool created by philosopher John MacFarlane. The book's visual style emulates the famous designs of Edward Tufte, thanks to more software created by Yihui Xie, J. J. Allaire, and many others who adapted Tufte's designs to HTML and PDF (via $\rm\LaTeX$).

If it weren't for all these tools, I never would have written this book. It wouldn't have been possible to create a book that does all the things this books is meant to do. I also owe inspiration to Kieran Healy, whose wonderful book [*Data Visualization: A Practical Introduction*](http://socviz.co/) uses the same suite of tools. His book gave me the idea to use them for an updated, open, and visually enhanced rendition of the classic material from Skyrms and Hacking.