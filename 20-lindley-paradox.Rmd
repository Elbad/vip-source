# Lindley's Paradox

```{block, type="epitaph"}
When you have eliminated all which is impossible, then whatever remains, however improbable, must be the truth.\
---Sherlock Holmes
```

Significance testing is all about deciding whether the data would have to be too much of a coincidence for the hypothesis to be true. But how much of a coincidence is too much? Should we reject a hypothesis when we find results that are significant at the $.05$-level? At the $.01$-level?


## Significance & Subjectivity

There seems to be a subjective element here. Researchers in the social sciences have mainly adopted $.05$ as the conventional cutoff. In other sciences the convention is to use $.01$. But we saw there's nothing special about these numbers (except they're easy to estimate without the help of a computer).

But it makes a big difference what cutoff we use. The lower the cutoff, the less often a result will be deemed significant. A lower cutoff means fewer hypotheses ruled out, which means fewer potential scientific discoveries.

Think of all the studies of potential cancer treatments being done around the world. In each study, the researcher is testing the hypothesis that their treatment has no effect, in the hopes of disproving this hypothesis. They're hoping enough patients get better in their study to show the treatment genuinely helps. If only a few more patients improve with their treatment compared to a placebo, it could just be a fluke. But if a lot more improve, that means the treatment is probably making a real difference.

The lower the significance level, the more patients have to improve before they can call their study's results "significant". So a lower significance level means fewer treatments will be adopted by the medical community. That might seem like a bad thing, but it has a big upside. It also means fewer *bogus* treatments being adopted.

```{marginfigure}
Medical treatments are often expensive, painful, or dangerous. So it's a serious problem to approve ones that don't actually work.
```

After all, some studies will see lots of patients improve just by luck. When that happens, the medical community adopts a treatment that doesn't actually work. And there might be lots of studies out there experimenting with treatments that don't actually help. If we do enough studies, we're bound to get flukey results in some of them, and adopt a treatment that doesn't actually work by mistake.

The moral: when we choose where to set the cutoff, we're choosing based on "subjective" assumptions. How many studies do we suspect are researching treatments that don't actually work? If it's only a few, then we can set the significance level higher, since we don't have to worry so much about approving bogus treatments. But if we suspect there are lots of bogus treatments being tried out, then we should set the significance level lower. Otherwise, we're liable to approve lots of useless treatments, maybe even some harmful ones.

Critics conclude that frequentism faces exactly the same subjectivity problem as Bayesianism. Bayesians use Bayes' theorem to evaluate hypothesis $H$ in light of evidence $E$:
$$ \p(H \given E) = \p(H) \frac{\p(E \given H)}{\p(E)} .$$
But we saw there's no recipe for calculating the prior probability of $H$, $\p(H)$. You just have to start with your best guess about how plausible $H$ is. Likewise, frequentists have to start with their best guess about how many of the potential cancer treatments being studied are bogus, and how many are real. That's how we decide where to set the cutoff for statistical significance.

From a Bayesian point of view, significance testing basically focuses on just one term in Bayes' theorem, the numerator $\p(E \given H)$. We suppose the hypothesis is true, and then consider how likely the sort of outcome we've observed is. But Bayes' theorem tells us that we need additional information to find what we really want, namely $\p(H \given E)$. We need to know $\p(H)$, how plausible $H$ is to begin with. Before we do the study, how likely is it this cancer treatment actually works?

This critique of frequentism is sharpened by a famous problem, Lindley's paradox.


## Lindley's Paradox

```{marginfigure}
This example comes from Howson & Urbach's *Scientific Reasoning: A Bayesian Approach*, who draw it from Kyburg. TODO: flesh out this citation.
```

Suppose a florist receives a large shipment of tulip bulbs with the label scratched off. The company that sent the shipment only sends two kinds of shipments. The first kind contains $25\%$ red bulbs, the second kind has $50\%$ red bulbs.

The two kinds of shipment are equally common. So the store owner figures this shipment could be of either kind, with equal probability.

To figure out which kind of shipment she has, she takes a sample of $48$ bulbs and plants them to see what colour they grow. $36$ grow red. What should she conclude? Intuitively, this result fits much better with the $50\%$ hypothesis than the $25\%$ hypothesis. So she should conclude she got the second, $50\%$ kind of shipment. (It's just a coincidence that significantly more than half red bulbs in her experiment.)

But if she uses significance testing, she won't get this result. In fact she won't get *any* result. Why not? Let's see.

Our florist starts by testing the hypothesis that 25% of the bulbs in the shipment are red. She starts by calculating $\mu$ and $\sigma$:
$$
  \begin{aligned}
    \mu    &= np\\
           &= (48)(1/4)\\
           &= 12,\\
    \sigma &= \sqrt{np(1-p)}\\
           &= \sqrt{(48)(1/4)(3/4)}\\
           &= 3.
  \end{aligned}
$$
The $99\%$ range is $12 \pm (3)(3)$, or from $3$ to $21$, and her finding of $k = 36$ is nowhere close to this range. So the result is significant at the $.01$ level. She rejects the $25\%$ hypothesis.

So far so good, but what if she tests the $50\%$ hypothesis too? She calculates the new $\mu$ and $\sigma$:
$$
  \begin{aligned}
    \mu    &= np\\
           &= (48)(1/2)\\
           &= 24,\\
    \sigma &= \sqrt{np(1-p)}\\
           &= \sqrt{(48)(1/2)(1/2)}\\
           &\approx 3.5.
  \end{aligned}
$$
So her result $k = 36$ is significant at the $.01$ here too! The $99\%$ range is $13.5$ to $34.5$, which doesn't include $k = 36$. So she rejects the $50\%$ hypothesis too.

But now she's rejected the only two possible hypotheses! There were only two kinds of shipment, and she's ruled them both out. Something seems to have gone wrong.


## A Bayesian Analysis

Bayesians will happily point out the source of the trouble: our florist has ignored the prior probabilities. If we use Bayes' theorem instead of significance testing, we'll find that the store owner should believe the second hypothesis, which seems right. $36$ red bulbs out of $48$ fits much better with the $50\%$ hypothesis than with the $25\%$ hypothesis.

How do we apply Bayes' theorem in the tulip example? First we label our two hypotheses and the evidence:
$$
  \begin{aligned}
    H      &= \mbox{$25\%$ of the bulbs are red},\\
    \neg H &= \mbox{$50\%$ of the bulbs are red,}\\
    E      &= \mbox{Out of 48 randomly selected bulbs, 36 grew red.}
  \end{aligned}
$$
We already know the prior probabilities of our hypotheses:
$$
  \begin{aligned}
    \p(H) &= 1/2,\\
    \p(\neg H) &= 1/2.
  \end{aligned}
$$
So we just need to calculate $\p(E \given H)$ and $\p(E \given \neg H)$. That's actually not so easy, but with the help of a computer we get:
$$
  \begin{aligned}
    \p(E \given H) &\approx 4.7 \times 10^{-13},\\
    \p(E \given \neg H) &\approx 2.5 \times 10^{-4}.
  \end{aligned}
$$
So we plug these numbers into Bayes' theorem:
$$
  \begin{aligned}
    \p(H \given E) &= \frac{\p(E \given H)\p(H)}{\p(E \given H)\p(H) + \p(E \given \neg H)\p(\neg H)}\\
        &\approx \frac{(4.7 \times 10^{-13})(1/2)}{(4.7 \times 10^{-13})(1/2) + (2.5 \times 10^{-4})(1/2)}\\
        &\approx .000000002,\\
    \p(\neg H \given E) &= \frac{\p(E \given \neg H)\p(\neg H)}{\p(E \given \neg H)\p(\neg H) + \p(E \given H)\p(H)}\\
        &\approx \frac{(2.5 \times 10^{-4})(1/2)}{(2.5 \times 10^{-4})(1/2) + (4.7 \times 10^{-13})(1/2)}\\
        &\approx .999999998.
  \end{aligned}
$$
Conclusion: the probability of the first hypothesis $H$ has gone way down: from $1/2$ to about $.000000002$. But the probability of the second hypothesis $\neg H$ has gone way up from $1/2$ to about $.999999998$! So we should believe the second hypothesis, not reject it!

According to Bayesian critics, this shows that significance testing is misguided. It ignores crucial background information. In this example, there were only two possible hypotheses, and they were equally likely. So whichever one fits the results best is supported by the evidence. In fact, the second hypothesis is *strongly* supported by the evidence, even though it fits the result quite poorly! The trouble with significance testing is that it can't respond to such subtleties.


## Exercises {-}

#. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. 

#. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.